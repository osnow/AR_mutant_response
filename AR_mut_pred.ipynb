{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Four_class_full_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "k-WR_bXlnqbY",
        "xbIROahdURrh",
        "_tXIKel0UaGU",
        "Loal8b3SEWNn",
        "JPcN8Py_p2Ov",
        "OcvjwxS9ERnX"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osnow/AR_mutant_response/blob/master/AR_mut_pred.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx12ph5PmclF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
        "from sklearn.model_selection import KFold, LeaveOneOut, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, roc_curve, auc, roc_auc_score\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOdg0hq4nltQ",
        "colab_type": "text"
      },
      "source": [
        "#Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MJIfZFNnpiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fingerprints = pd.read_csv('path_to_data/Morg_FPs.csv',index_col=0)\n",
        "#fingerprints = fingerprints.loc[:, fingerprints.var() != 0.0] #remove zero variance columns\n",
        "\n",
        "zscales = pd.read_csv('path_to_data/zscale.csv',header=None)\n",
        "zscales = zscales.iloc[:,1:]\n",
        "#zscales = zscales.loc[:, zscales.var() != 0.0] #remove zero variance columns\n",
        "\n",
        "classes = pd.read_csv('path_to_data/all_muts_classes_updated.csv', index_col=0)\n",
        "zscales.index = classes.name\n",
        "\n",
        "merged = fingerprints.merge(zscales,left_index=True,right_index=True)\n",
        "print(merged.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEfOaUBiuLb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "merged.values[:5,2048:].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuTFmH19J17f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "ODM_data = pd.read_csv('path_to_data/ODM_mutants_train.csv',index_col=0)\n",
        "ODM_classes = ODM_data.pop('class')\n",
        "\n",
        "ODM_data.columns = merged.columns\n",
        "print(ODM_data.shape)\n",
        "\n",
        "X = pd.concat([merged, ODM_data])\n",
        "print(X.shape)\n",
        "\n",
        "y = pd.concat([classes['class'], ODM_classes])\n",
        "print(y.shape)\n",
        "dummy_y = np_utils.to_categorical(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRQu0n698eT3",
        "colab_type": "text"
      },
      "source": [
        "# Make ODM mutant validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPtD-bCS4PLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create odm mutant zscales from the bica mutants\n",
        "odm_zscales = zscales.iloc[:45,:].drop('wt_bic')\n",
        "# change index name \n",
        "odm_zscales.index = odm_zscales.index.str.split('_').str[0]+'_odm'\n",
        "odm_zscales.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXIf0-hQ75ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creat matrix of only odm fingerprints \n",
        "odm_fp = fingerprints.loc['d880e_odm',:].values\n",
        "fps = pd.DataFrame([odm_fp]*44)\n",
        "# combine fps and zscales\n",
        "odm_new_muts = np.hstack((fps,odm_zscales))\n",
        "# convert to DF with names as index\n",
        "odm_new_muts = pd.DataFrame(data=odm_new_muts,index=odm_zscales.index) \n",
        "odm_new_muts['class'] = odm_truth['Ground truth'].values # add classes column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FCRT8ZWvZja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "odm_new_muts.to_csv('path_to_data/ODM_mutants_train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-WR_bXlnqbY",
        "colab_type": "text"
      },
      "source": [
        "#Build NN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe6OJTEQmlQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(neurons1=128, neurons2=32, epochs=100,dropout1=0.1,dropout2=0.1,mbs=16):\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(neurons1, input_dim=X.shape[1], kernel_initializer='he_normal', activation='relu'))\n",
        "    model.add(Dropout(dropout1))\n",
        "    model.add(Dense(neurons2, kernel_initializer='he_normal', activation='relu'))\n",
        "    model.add(Dropout(dropout2))\n",
        "    model.add(Dense(4, kernel_initializer='he_normal', activation='softmax'))\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCUer4f3Ue26",
        "colab_type": "text"
      },
      "source": [
        "# Column Transformer and over sample "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G9NUDW0_EkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import dump\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train_res[:,2048:])\n",
        "dump(scaler, open('path_to_data/scaler.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6uMtGe4Uj1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.compose import make_column_transformer \n",
        "\n",
        "ct = make_column_transformer(\n",
        "        (StandardScaler(), slice(2048,4148)) # make sure this shape matches zscales\n",
        "    ,remainder='drop',verbose=True)\n",
        "\n",
        "BSmote = BorderlineSMOTE()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbIROahdURrh",
        "colab_type": "text"
      },
      "source": [
        "# Run Random CV pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckfUFdPGcbNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "# create model\n",
        "estimators = []\n",
        "estimators.append(('standardize', ct))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_model, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "# define the grid search parameters\n",
        "neurons1 = [256, 128, 64, 32]\n",
        "neurons2 = [32, 16, 8]\n",
        "epochs = [10, 20, 50, 100, 150]\n",
        "mbs = [8, 16, 32, 64]\n",
        "dropout1 = [0.0, 0.01, 0.1, 0.2, 0.3]\n",
        "dropout2 = [0.0, 0.01, 0.1, 0.2, 0.3]\n",
        "param_grid = dict(mlp__neurons1=neurons1, mlp__neurons2=neurons2,mlp__epochs=epochs,mlp__dropout1=dropout1,mlp__dropout2=dropout2,mlp__mbs=mbs,mlp__class_weight=[class_weight,'auto'])\n",
        "search = RandomizedSearchCV(estimator=pipeline, param_distributions=param_grid, n_jobs=1, cv=5, n_iter=25)\n",
        "search_result = search.fit(X, dummy_y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (search_result.best_score_, search_result.best_params_))\n",
        "means = search_result.cv_results_['mean_test_score']\n",
        "stds = search_result.cv_results_['std_test_score']\n",
        "params = search_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tXIKel0UaGU",
        "colab_type": "text"
      },
      "source": [
        "# CV pipeline with plotted curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-nE7ZmvEQTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls_mb_size = [8, 16, 32, 64]\n",
        "ls_epoch = [10, 20, 50, 100, 150]\n",
        "ls_rate = [0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.08, 0.1, 0.2, 0.3]\n",
        "ls_h_dim1 = [256, 128, 64, 32]\n",
        "ls_h_dim2 = [64, 32, 16, 8]\n",
        "acts = ['relu', 'elu']\n",
        "\n",
        "max_iter = 25\n",
        "save_results_to = './val_curves/'\n",
        "\n",
        "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
        "for iters in range(max_iter):\n",
        "    \n",
        "    mbs = np.random.choice(ls_mb_size)\n",
        "    hdm1 = np.random.choice(ls_h_dim1)\n",
        "    hdm2 = np.random.choice(ls_h_dim2)\n",
        "    epoch = np.random.choice(ls_epoch)\n",
        "    rate1 = np.random.choice(ls_rate)\n",
        "    rate2 = np.random.choice(ls_rate) \n",
        "    act = np.random.choice(acts)\n",
        "\n",
        "    k = 0\n",
        "\n",
        "    for tr_ind, ts_ind in kf.split(X.values):\n",
        "        k = k + 1\n",
        "\n",
        "        ct.fit(X.values[tr_ind,:])\n",
        "        X_train_trans = ct.transform(X.values[tr_ind,:])\n",
        "        X_test_trans = ct.transform(X.values[ts_ind,:])\n",
        "        X_train = np.hstack((X.values[tr_ind,:210],X_train_trans))\n",
        "        X_test = np.hstack((X.values[ts_ind,:210],X_test_trans))\n",
        "        \n",
        "        X_train, y_train = BorderlineSMOTE().fit_resample(X_train, dummy_y[tr_ind,:])\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(hdm1, input_dim=X_train.shape[1], kernel_initializer='he_normal', activation=act))\n",
        "        model.add(Dropout(rate1))\n",
        "        model.add(Dense(hdm2, kernel_initializer='he_normal', activation=act))\n",
        "        model.add(Dropout(rate2))\n",
        "        model.add(Dense(4, kernel_initializer='he_normal', activation='softmax'))\n",
        "        #model.summary()\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "        history = model.fit(X_train, y_train, epochs=epoch, batch_size=mbs,  verbose=0, validation_data=(X_test,dummy_y[ts_ind,:]))\n",
        "        \n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        title2 = 'Loss Train iter = {}, fold = {}, mb_size = {},  epoch = {}, rate = ({},{}), dim = ({},{}), act = {}'.\\\n",
        "                          format(iters, k, mbs, epoch, rate1, rate2, hdm1, hdm2, act)\n",
        "        plt.title(title2)\n",
        "        plt.ylabel('loss')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'validation'], loc='upper left')\n",
        "        plt.savefig(save_results_to + title2 + '.png', dpi = 150, bbox_inches = 'tight')\n",
        "        plt.close()\n",
        "    K.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Loal8b3SEWNn",
        "colab_type": "text"
      },
      "source": [
        "#Retrain with best params and predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cYSDSXWXdOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X.loc[~X.index.str.contains('odm'),:]\n",
        "X_test = X.loc[X.index.str.contains('odm'),:]\n",
        "y_train = dummy_y[~X.index.str.contains('odm'),:]\n",
        "y_test = dummy_y[X.index.str.contains('odm'),:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M1gZM1G7_I2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train on whole dataset (no split)\n",
        "X_train, y_train = X, dummy_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bcE79bMcnrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,dummy_y, test_size=0.2, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnsrvdbRyBes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_res, y_train_res = BorderlineSMOTE().fit_resample(X_train, y_train)\n",
        "#X_train_res, y_train_res = X_train, y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOY95QoU8_f2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_trans = ct.fit_transform(X_train_res)\n",
        "#X_test_trans = ct.transform(X_test)\n",
        "X_train = np.hstack((X_train_res[:,:2048],X_train_trans))\n",
        "#X_test = np.hstack((X_test.iloc[:,:210],X_test_trans))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip78J38ifN5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model callbacks \n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='auto')\n",
        "mc = ModelCheckpoint(filepath='path_to_model/best_model_new.h5', monitor='val_accuracy', mode='auto', verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-mL5AwnEdDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create and fit on train data using best hyperparameters \n",
        "model = create_model(neurons1=128,neurons2=32,epochs=50, dropout1=0.01,dropout2=0.01, mbs=32)\n",
        "model.fit(X_train,y_train_res,verbose=1,epochs=100,batch_size=16,validation_split=0.2, callbacks=[early_stopping,mc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyhPgXl0sa7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RF baseline Train and test \n",
        "random_state = np.random.RandomState(0)\n",
        "model = RandomForestClassifier(n_estimators=50,max_depth=10, random_state=random_state,verbose=0,n_jobs=-1)\n",
        "model.fit(X_train,y_train_res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGRTlvOTQJVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SVM baseline Train and Test\n",
        "model = OneVsRestClassifier(svm.SVC(kernel='rbf', C= 100, gamma = .001, probability=True,\n",
        "                                 random_state=random_state))\n",
        "model.fit(X_train,y_train_res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPcN8Py_p2Ov",
        "colab_type": "text"
      },
      "source": [
        "# ODM predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMGC71aImmzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compare preds to ground truth\n",
        "odm_truth = pd.read_csv('path_to_results/ODM_predictions.csv')\n",
        "y_true = odm_truth['Ground truth']\n",
        "y_pred = odm_truth['Predicted']\n",
        "\n",
        "report = classification_report(y_true, y_pred, output_dict=True,zero_division=0)\n",
        "print(\"Test Report\", report)\n",
        "cr = pd.DataFrame(report).transpose()\n",
        "cr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsJ0BHTaGtvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict on ODM external validation set \n",
        "saved_model = load_model('best_model.h5')\n",
        "odm_pred = saved_model.predict(X_test)\n",
        "pred_classes = np.argmax(odm_pred, axis=1)\n",
        "odm_pred_classes = pd.DataFrame(pred_classes,index=odm_zscales.index)\n",
        "#odm_pred_classes.to_csv('/content/drive/My Drive/2019-McGill-Mutants/ODM_predictions.csv')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfXSeH_qcnU4",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate model and produce results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56pJbjIJi1nV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train and test accuracy \n",
        "model = load_model('best_model.h5')\n",
        "_, train_acc = model.evaluate(X_train, y_train_res, verbose=0)\n",
        "_, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AG6tpaCuQOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get results and report\n",
        "y_pred_train = model.predict_proba(X_train)\n",
        "y_pred_test = model.predict_proba(X_test)\n",
        "\n",
        "# report accuracy\n",
        "y_pred = np.argmax(y_pred_test, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "report = classification_report(y_true, y_pred, output_dict=True)\n",
        "print(\"Test Report\", report)\n",
        "cr = pd.DataFrame(report).transpose()\n",
        "cr.to_csv('DNN_class_report.csv')\n",
        "cr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcvjwxS9ERnX",
        "colab_type": "text"
      },
      "source": [
        "#Plot confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyXaalId-wJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mlxtend.evaluate import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_target=y_true, \n",
        "                      y_predicted=y_pred, \n",
        "                      binary=False)\n",
        "\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
        "ax.set_xticklabels(['','non-resp.','antag.', 'agonist', 'mixed'])\n",
        "ax.set_yticklabels(['','non-resp.','antag.', 'agonist', 'mixed'])\n",
        "plt.savefig('SVM_test_CM.eps',dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD9pYQsPp8Ul",
        "colab_type": "text"
      },
      "source": [
        "# ROC curve with baselines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "td5_e9UI_oOQ",
        "colab": {}
      },
      "source": [
        "\n",
        "fig = plt.figure(figsize=(15,8))\n",
        "random_state = np.random.RandomState(0)\n",
        "\n",
        "kfold = KFold(n_splits=5, random_state=random_state, shuffle=True)\n",
        "\n",
        "\n",
        "# Define baselines and NN \n",
        "svm_clf = OneVsRestClassifier(svm.SVC(kernel='rbf', C= 100, gamma = .001, probability=True,\n",
        "                                 random_state=random_state))\n",
        "rf_clf =  OneVsRestClassifier(RandomForestClassifier(n_estimators=50,max_depth=10, random_state=random_state,verbose=0,n_jobs=-1))\n",
        "NN_clf = KerasClassifier(build_fn=create_model)\n",
        "\n",
        "# DNN model callbacks \n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='auto')\n",
        "mc = ModelCheckpoint(filepath='./best_model.h5', monitor='val_acc', mode='auto', verbose=0, save_best_only=True)\n",
        "\n",
        "names = ['SVM', 'RF', 'DNN']\n",
        "classifiers = [svm_clf, rf_clf, NN_clf]\n",
        "\n",
        "for i, classifier in enumerate(classifiers):\n",
        "    tprs = []\n",
        "    aucs = []\n",
        "\n",
        "    fold = 0\n",
        "    for train, test in kfold.split(X, dummy_y):\n",
        "        X_train_res, y_train_res = BorderlineSMOTE().fit_resample(X.iloc[train,:], dummy_y[train,:])\n",
        "        \n",
        "        X_train_trans = ct.fit_transform(X_train_res)\n",
        "        X_test_trans = ct.transform(X.iloc[test,:])\n",
        "        X_train = np.hstack((X_train_res[:,:210],X_train_trans))\n",
        "        X_test = np.hstack((X.iloc[test,:210],X_test_trans))\n",
        "\n",
        "        if classifier == NN_clf:\n",
        "            classifier.fit(X_train, y_train_res,callbacks=[early_stopping,mc],epochs=100,validation_split=0.2)\n",
        "            #classifier = load_model('best_model.h5')\n",
        "            probas_ = classifier.predict_proba(X_test)\n",
        "        elif classifier == rf_clf:\n",
        "            probas_ = classifier.fit(X_train, y_train_res).predict_proba(X_test)\n",
        "        elif classifier == svm_clf:\n",
        "            probas_ = classifier.fit(X_train, y_train_res).decision_function(X_test)   \n",
        "        \n",
        "        # Compute ROC curve and ROC area for each class\n",
        "        fpr = dict()\n",
        "        tpr = dict()\n",
        "        roc_auc = dict()\n",
        "        #for i in range(4):\n",
        "            #fpr[i], tpr[i], _ = roc_curve(y_train_res[test, i], probas_[:, i])\n",
        "            #roc_auc[i] = roc_auc_score(y_train_res[test, i], probas_[:, i],average='weighted')\n",
        "\n",
        "        # Compute micro-average ROC curve and ROC area\n",
        "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(dummy_y[test].ravel(), probas_.ravel())\n",
        "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "        roc_auc['micro'] = roc_auc_score(dummy_y[test], probas_,average='weighted')\n",
        "        \n",
        "        mean_fpr = np.linspace(0, 1, 100)\n",
        "\n",
        "        # append to list and plot for each fold\n",
        "        tprs.append(interp(mean_fpr, fpr['micro'], tpr['micro']))\n",
        "        tprs[-1][0] = 0.0\n",
        "        aucs.append(roc_auc[\"micro\"])\n",
        "        #plt.plot(fpr['micro'], tpr['micro'], lw=2, alpha=0.3,\n",
        "         #       label='ROC fold %d (AUC = %0.2f)' % (fold+1, roc_auc[\"micro\"]))\n",
        "        \n",
        "        fold += 1\n",
        "\n",
        "    mean_tpr_cv = np.mean(tprs, axis=0)\n",
        "    mean_tpr_cv[-1] = 1.0\n",
        "    mean_auc = auc(mean_fpr, mean_tpr_cv)\n",
        "    std_auc = np.std(aucs)\n",
        "    plt.plot(mean_fpr, mean_tpr_cv,\n",
        "            label=r'%s ROC (AUC = %0.2f $\\pm$ %0.2f)' % (names[i], mean_auc, std_auc),\n",
        "            lw=2, alpha=.8)\n",
        "\n",
        "    std_tpr = np.std(tprs, axis=0)\n",
        "    tprs_upper = np.minimum(mean_tpr_cv + std_tpr, 1)\n",
        "    tprs_lower = np.maximum(mean_tpr_cv - std_tpr, 0)\n",
        "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2)\n",
        "                    #,label=r'$\\pm$ 1 std. dev.')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
        "            label='Chance', alpha=.8)\n",
        "plt.xlim([-0.05, 1.05])\n",
        "plt.ylim([-0.05, 1.05])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4kR6a_gAR7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.xlabel('False Positive Rate',fontsize='20')\n",
        "plt.ylabel('True Positive Rate',fontsize='xx-large')\n",
        "plt.title('ROC 5-fold CV Comparison', fontsize='xx-large')\n",
        "plt.legend(loc=\"lower right\",fontsize=20)\n",
        "plt.savefig('ROC5fold_All_Oversampled_inloop.png',dpi=300)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}